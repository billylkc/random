#+STARTUP: showall

* Review
- IAM
- Logging
- Network
- Case study
- Reference architecture (https://cloud.google.com/architecture/mobile-gaming-analysis-telemetry)

* New Case Study
** Helicopter Racing League
*** Background
- global, regional competitions
- stream
- predictions
- migrate existing service
- expand the use of AI and ML services
- serve contents closer to their users. Latency
- Multi-cloud
- Transcode content
- Good connectivity
- Video encoding performed by VMs
- TensorFlow running on VMs
- Expose predictive models to partners
- additional insights

** EHR Healthcare
*** Background
- Software as a servide to multi-national medical offices, hospitals. and insurance provider
- Scale, DR plan, roll out CI/CD
- Inhouse facilities
- Web based customer facing
- Kubernetes clusters'
- Mixture of relational and NoSql database (MySql, MS SQL Server, Redis, and MongoDB)
- Legacy file and API-based intergrations with insurance providers on-premises. No plan to upgrade this
- Microsoft Active Directory
- HA
- Centrlize visibility and practive action on sustem performace and usage
- compliancy
- prediction on industry trends
- provide consistent way to manage customer-facing applcations that are container based
- High performace connection between on premises and GCP
- logging
- Dynamically scale and provision to new environments.

** Mountkirk Games
*** Background
- First person shooter game
- Geo specific arena
- Global leaderboard
- GKE
- Global LB, cloest regional game arena
- multi region Spanner cluster
- lift and shift VM migration
- new game isolated GCP folder
- rapid iteration of game features
- dynamic scaling
- GPU processing to render graphics server side for multi-platform support
- Support event migration of legacy games to this new platform
- Latency is top priority

** TerramEarth
*** Background
- 500 dealers, service 100 countries, 2 million vehicles
- Each vehicles genreates 200 to 500 megabytes of data per day
- sensor data is captured from two main maufaturing plants, have multiple network interconnects to GCP
- Web front-end
- predict failure for JIT repair
- Modernize CI/CD pipelines
- Decreas cloud operational costs and adapt to seasonality
- Increase speed and reliability of development workflow
- Allow remote developers to be productive without compromising code or data security
- Create a flexible and scalable platform for developers to create custom API servides for dealers and partners
- Create a new abstraction layer for HTTP API access to their legacy sustems to enable gradual move into the cloud without disrupting operations
- Create a self service portal for interal and partner develpers to create new projects request resources for data analysis and centrall maage access to the API endpoints
- cloud native solutions for keys and secrets management and optimize for identiy-based access
- Improve and standardize tools for application and netowrk monitoring and troubleshooting


* Old Case study

** Mountkirk Games
*** Background
- Huge player base, game events
- Dynamically scale up or down based on game activity
- Connect to a traditional database service to manage user profiles and game states
- Store game acitivity in a time-series service for future analysis
- capture, transfer, archive, real time
- JSON
- Many small service, able to roll back quickly
- Service are deployed redundantly across multiple regions in US and Europe
- Real time analytic platform
- Only fronend service are exposed to public internet
- Customized Linux distro

*** Solution
- Pub/Sub
- Cloud Dataflow (Batch and Stream)
- Cloud Datastore
- Cloud Storage
- BigQuery

- Cloud Registry, GKE, HTTPS LB
- Game back end - Managed Insance Group on Compute Engine
- Differernt projects for development, staging and production

*** Others
- Create a scalable environment in GCP for simulating production load

** Dress4win
*** Background
- Mysql
- CI/CD
- Disaster Recovery
- Managed logging and monitoring
- Apache Hadoop/Spark Servers
- Support failover of production environment
- Support multiple VPN connections between production center and cloud environment
- Use managd service wherever possible
- Encrypt data on the wire and at rest

*** Soloution
- Cloud SQL
- Cloud Build
- GKE (?)

- Setup Cloud VPN and DNS

*** Others
- Stackdriver dashboard not healthy
  In Cloud Platform Console download the list of the uptime servers' IP address and create an inbound firewall rules

- Service as Regional, with the possibiliy of multi-regional HA, health-checking, auto failover, etc

- Possible replicate of on-premises database and Cloud database

- Prepare custom image of DB server by stoping the instance

- Run current jobs from current technical environment on Cloud Dataproc

- Load data from Cloud Storage to BigQuery, date partitioned table

- Recommend to deploy with smallest instance available, monitor over time, scakes up until desired performance is reached

- Store image files in a Cloud Storage Bucket. Use Cloud Datastore to maintain metadata that maps each customer's ID and their image files

- Use gcsfuse(FUSE) to mount a Google Cloud Storage Bucket as a volume directly on the instance and write ackups to the mounted location using mysqldump

** TerramEath
*** Background
- gzip csv file to ftp
- unplanned verhicle downtime to minimum
- transform and get statistical figures immediately
- Store everything in Data Warehouse or Datalake in most suitable way
- Use current routine whenever possible

*** Solution
- Pub/sub
- Cloud Dataflow
- Cloud Storage
- BigQuery
- Cloud Composer

*** Flow
1. Real time events from mobile
2. Authentication (App Engine)
3. Cloud Pub/Sub
4. Cloud Dataflow
5. BigQuery
6. Cloud Datalab
7. Batch upload to Cloud Storage


*** Others
1. Signigicant change if adpatation
   - Capacity planning
   - TCO calculations
   - Opex and Capex allocation

2. Reduce customer wait time
   - Increase fleet cellular connectivity to 90%
   - migrate from FTP to streaming
   - Deploy ML analysis of metrics

3. Launch a cluster in each region to preprocess and compress the raw data, then move to a regional bucker and use Cloud Dataproc cluster

4. Increase operational efficiency
   Capture all opearting data, train ML model, run locally to make operational adjustment automatically

5. Directly transfer the files to a different Google Cloud Regional bucket location in US, EU, and Asia using Google APIs over HTTPS. Run the ETL process to retrieve the data from each Regional bucket.

6. Use App Engine with Google Cloud Endpoints. Focus on an API for dealers and partners.

7. Have the vehicle's computer compress the data in hour snapshots, store it in a GCS Codeline bucket

* Random stuff
** Sensitive stuff
Cloud DLP

** Shutdown script
- shutdown script, metadata, create vm

** Increase persistent disk for vm
- resize2fs command
- Atomatic storage increase

* IAM ffs
- Reference
  gcloud iam roles describe

- Workload identity

** Bigquery
- bigquery. , bigquery.datasets.create
- bigquery.jobs.create - create a view of data you do not own
- Logging/Private Logs Viewer / Project Owner / Project Viewer

- bigquery.owner - read, update, delete, create

- bigquery.dataViewer - monitor size of all tables across all projects

- Set up logging export
  - Set up export to BigQuery. Set up partition expiration to limit storage cost
  - Turn on audit logging
  - Configure the logging export
  - Setup IAM policy permission for BigQuery dataset

** Compute Engine
- Compute Instance Admin role vs Compute Admin

** Transfer service to BQ
- bigquery.transfer.update, bigquery.transfer.get, bigquery.datasets.update

** Security team
- org viewer, project viewer

** Cloud Composer
- storage.objectAdmin to upload file
- may need composer.environments.get to look up DAG buckets

** Share backup, images
- Image:     roles/compute.imageUser, compute.images.useReadOnly
- Snapshots: roles/compute.storageAdmin, compute.snapshots.useReadOnly
- Disk:      roles/compute.sotrageAdmin, compute.disks.useReadOnly

** Folder
- **No Such things** as IAM folder
- Folder not used to organize access privileges/users

** Security team
Org viewer, project viewer

** VPC
- Shared VPC admin role (needed to setup shared VPC)
- all the shared VPC is available of user irrespective of subnet level sharing permission
- Each subnet can span at least 2 Availability zone to provide a HA environment
- By default, all subnets can route between each other, whether thry are private or public

** Small company
Create a new Google Group and add all users to the group. Use "gcloud projects add-iam-policy-binding" with the Project Viewer row and Group email address

* Products

** Reference
https://cloud.google.com/products

** Networking
*** Others
- Both directions

*** Shared VPC
- Connects Projects within same organization
- Host project, service project

- Compute Shared VPC admin and Project IAM Admin
- compute.networkUser, instance admin

*** VPC Peering
- network stays within Google
- Communicate between organization, projects,..

*** NAT instance or Cloud NAT gateway
- or Baston Host
- Update server, etc

*** Google Cloud Dedicated Interconnect or Google Cloud partner Interconnect
- in your VPC
- With SLA

*** Peering (Direct Peering, Carrier Peering)
- no SLA

*** Cloud interconnect (10Gbps-100Gbps)
- Close to edge point
- Partner if not close

*** Cloud VPN tunnel / Cloud interconnect (3 Gbps)
- static routing and dynamic routing
- BGP (Boarder Gateway Protocol)
- VPC network DO NOT have any IP address ranges associated with them
- Hybrid environment
- Connect to on premises (?)

** Data migration
*** gsutil ( < 1 TB)
- one time or manually initiated transfer
- error, continue *(-c)*
- split and parrallel *(-o)* (?)
- manifest log file *(-L)*
- multi-thread transfer *(-m)*
- Automatic synchronizaton of local directory (rsync)
- Resumable uploads
- Parallel upload *(-m)*
- retires, resume, parrallel composite uploads, etc
- gsutil lifecylce set [json file] gs://[bucket_name]

*** Storage Transfer Service (1 TB - 10 TB)
- e.g. daily from Amazon S3, HTTP/HTTPS service (1TB - 10TB)
- Online data
- Sync files between source and sink
- Move file based onfilter
- Schedule periodic data transfer

*** Transfer Aliance (90 TB)
- Data Rehydration
- Large volume transfer


*** Migrate for Anthos
- Component for migrating VMs into syetem containers on GKE

*** Scalable for small company
1 Cloud VPN Gateway, 1 Peer Gateway, 1 Cloud Router


** Load Balancer (LB) ffs
*** HTTP(S) LB
- HTTPS traffic
- Layer 7
- handle websocket traffic natively

*** TCP LB
- No SSL offload
- Layer 4

*** UDP LB
- Layer 4

*** Network TCP/UDP LB
- Preserve Client IP

*** SSL Proxy LB
- Global availabilty
- SSL offloading

*** Internal TCP/UDP LB
- Internal use

** Data Analytics

*** Pub/Sub
- Messaging service

*** Cloud Dataprep
- *Limited functionality*
- Service to prepare data for analysis and ML
- ETL (?)

*** Cloud Dataflow
- *Apache Beam*
- Streaming and batch processing

*** Cloud Dataproc
- *fully managed*
- Service to run *Spark* and Hadoop cluster

*** Cloud Composer
- Fully managed *workflow* orchestration
- Apache *Airflow*
- Support hybrid and multi-cloud
- DAG

*** Cloud Tasks
- Task management service for async task execution

*** Cloud Data Fusion
- Data integration for building and managing data pipeline

*** Data Catalog
- Metadata solution for exploring and managing data

** Machine learning

*** Machine learning
   - Cloud Natural Language API
   - Cloud Vision API - extract text, document tagging
   - Cloud Translation API
   - Cloud Speech API
   - Cloud Video Intelligence API

** Database

*** BigQuery
- Doesn't use indexes. Only full scan search.

- Columna

- Use Partitioned table, Clustered table, and Views (Important)

- Support query directly (External data source/Federated data source)
  + Does not guarentee consistency. esp changes while running query
  + Can not reference wildcard table
  + Bigtable
  + Cloud Storage
  + Google drive
  + Cloud SQL

- Support format
  + Avro
  + CSV
  + JSON (newly deliminated only)
  + ORC
  + Parquet

- Clustered tables (e.g. with Product type, Sale Region). Use sorted blocks to eliminate scans of unnecessary data.

*** Cloud Firestore
- document database
- Mobile, web, and IoT apps
- Regional with multi-region replication, if needed
- Automatic horizontal scaling
- Realtime database

*** Cloud Datastore
- NoSql database
- Good for game state, hierarchical data, user profile, product catelogs, etc..

*** Cloud Big Table
- **Time series**
- NoSql database
- For row key design patter, use tall and narrow tables
- Prefer reverse time stamp only if most common query is for latest value
- Design your row key with your queries in mind
- Low latency, high throughput
- high speed transaction and analysis
- Wide Column database

*** Cloud Spanner
- Global SQL database
- Transactional data

*** Cloud Functions
- **Serverless** execution environment to connect cloud services
- Simple, **single purpose** functions attached to events

*** Cloud SQL
- Fully managed database for Mysql, PostgreSQL and SQL server

** IoT
*** Edge IoT
*** IoT Core

** Containers

*** App Engine
- Language: Python, jave, Node js, PHP, GO
- Instance statup time  in seconds

*** Cloud Build
- Run tests, build container image
- Push to Cloud Registry
- CI/CD platform

*** Cloud Source Repository
- Private Git repository to store, manage, and track code
- Github, Bitbuckets, etc.

*** Cloud Run

*** Cloud Deployment Manager
- maanging resources in declarative format
- Only support automation in GCP
- Can be used to permanantly delete resources
- Allow different Cloud Platform service (Cloud storage, Cloud compute engine, etc..) to work together

*** GKE
- Use Workload Identity
- Money Saving because of less computing power required
- Allow Continuous Deployment with Cloud Build
- LB is more performant than Instance Group balancing
- *Can not chagne machine type* in a cluster. Need create new one and migrate

- Autoscaling - gcloud container clusters create CLUSTER_NAME --enable-autoscaling --min-nodes=1 --max-nodes=10
- Resize - gcloud container clusters resize CLUSTER_NAME --node-pol 'primary-node-pool' --num-nodes=20

- Docker to GKE
  - Setup a GKE cluster: gcloud container cluster create
  - Create a deployment: kubectl create deployment
  - Create a service:    kubectl expose deployment

- **ISTIO**
  - service abstraction for Pods, jobs, VM based application
  - Create a secure, zero trust network across cloud provider
  - Connect, monitor and secure microservices

*** Container Registry
- Execute build and product artifacts like Docker containers, Java archive, etc..

*** Cloud Scheduler
- Cron job scheduler for automation and management

*** Others
- Cloud Source Repository -> Cloud Build -> Container Registry <- Kubernetes Engine <- Cloud Build -< Deplotment Manifests

** Service account

1. Web application accessing GCP resorces
   - Cloud identity-Aware Proxy (IAP)
     - Application level access control

   - Service account credentials

2. Cross-charging BigQuery usage to different cost center
   - Project with labels

3. Managing service accounts used for operational and admin activities

** Others

1) Cloud Marketplace

2) Stackdriver Workspaces and Groups

3) HTTP errors
   + 307 - Temporary Redirect
   + 400 - Bad Request
   + 429 - Too Many Requests (Thrittle client's requests. Use truncated exponential backoff)
   + 401 - Unauthorized
   + 403 - Forbidden
   + 405 - Method not allowed
   + 500 - Internal Server Error
   + 502 - Bad ateway
   + 503 - Service Unavailable
   + 504 - Gateway Timeout

4) Cloud Function > App Engine Standard > GKE > Compute Engine with containers > Compute Engine
   Managed service

5) Preemptible VM
   gcloud compute instances create "preempt" --preemptible --no-boot-disk-auto-delete

6) Service account best practice
   - Do not delete service account that are in use by running instances on Google App Engine or Google Compute Engine
   - Use the diplay name *(purpose)* to keep track of service accounts
   - Create service accounts for each service with only the permissions required for that service
   - Audit service accounts and keys. serviceAccount.keys.list() or Logs Viewer page in onsole

7) VM relaunched every minutes
   - Ensure firewall rule exists to allow LB health checks to reach the instance in the instance group

8) Comliance
   - Add finance team to Billing Administrator role
   - Add developers to the Viewer role of the project

9) Local SSD
   - Can attach up to 24 local SSD for total *9TB per instance* (375 each)

10) Speed up VPN tunnel *(each 1.5 Gbps max)*
    - Create an additonal VPN tunnel

11) resize GKE cluster
    gcloud container clusters resuze

12) Billing
    Use BigQuery billing export and labesls to associate cost to groups

13) VPC Service Control
    - create security parameter around data stored in API-based GCp services
    - Mitigate data exfiltration risks stemming from stolen identities

14) Cloud Data Loss Prevention (DLP)
    - sensitive data
    - Credit card, social security numebr, etc..

15) Which service enabled
    gcloud services list / gcloud services list --enabled

16) Blue-gree deployment allows for extensive testing in green env before sending traffic to blue.

17) SAN -> Persistent Disk
    NAS (Network attached storage) -> Persistent Disk or Cloud storage

18) Cloud spanner
    metrics for Scaling CPU  (>70%)

19) Terraform, Anthos

20) Cloud Run, Cloud Function

21) Game server

** Logging
*** Stackdriver Monitoring
- Full-stack monitoring for GCP and AWS

*** Stackdriver Debugger
- Investigate code behaviour
- Inspect state of application at code location
- Similar to Chrome devtool
- Without stopping and slowing app

*** Stackdriver Profiler
- Statistical, low overhead profiler
- CPU, Memory usage
- Help identify the parts consuming most resoirces

*** Stackdriver Trace
- Find performance bottleneck
- Collect latency data
- Breakdown request latencies at each microservice
- What can i do to reduce application latency
- Display near realtime

*** Stackdriver Error Reporting
- Aggregates and report errors from running cloud services
- Identify and understand your application errors

*** Cloud logging
- Securely store, search, analyze and alert log data and events
- Ingest custom log data from any source

*** Cloud Audit log
- Admin activity logs
- Data access audit logs
- System event audit logs
- Policy Denied audit logs



* Cloud storage
- Immutable. No update and append.
- Global consistency
- Use domain name buckets. Manage bucket name as sub-domains.
- Use exponential back off as rery strategy.
- Nearline (min. 30 days), Coldline (min. 90 days), Archive Storage (min. 365 days)
- No Google account, can use signd URLs
- Does not support file appends and updates
- Cons: Not POSIX-compliant. (HDFS is not fully compliant as well)
- Can not use as CDN. another service.

* Security
DLP - Cloud data loss, sensitive data

* Resources
1) Compute engine - global, regional, zonal
2) image - global

- Global

  Addresses. Global address for load balancing
  Images
  Snapshots
  Instance templates
  Cloud interconnects
  Cloud interconnects locations
  VPC network
  Firewalls
  Routes

- Regional

  VPC  individual subnet
  interconnect attachemnts
  static external ip (?)
  Addresses - regional static external IP addresses
  *Subnets*
  Regional mapped instance group
  Regional persistent disks

- Zonal

  *instance*
  disk resources. Cant attach a disk in different zone.
  Persistent disks
  machine types
  Cloud TPU
  Dataproc
